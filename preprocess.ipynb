{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process pictures for *train*\n",
    "1. compute **nmf** for all wav files and save as `npy` file\n",
    "2. get **labels** as ground truth from `wav` files path and save as `npy` file\n",
    "3. save paths of all `npy` file in `train.h5` and `val.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from dataset.NMF import audio_import\n",
    "\n",
    "#indexes1 = ['accordion', 'acoustic_guitar', 'cello',  'flute',  'saxophone', 'trumpet', 'violin', 'xylophone']\n",
    "#indexes2 = [[401], [402], [486], [558], [776], [513], [889], [642]]\n",
    "#indexes3 = [[401], [402,546], [486], [558], [776], [513], [889], [642]]\n",
    "idxs=[401,402,486,513,558,642,776,889]\n",
    "names=['accordion','acoustic_guitar','cello','trumpet','flute','xylophone','saxophone','violin']\n",
    "\n",
    "path = 'h:/Study/bpfile/dataset/audios/'\n",
    "wav_files = []\n",
    "bases_filepath = []\n",
    "labels_filepath = []\n",
    "\n",
    "# 遍历数据集 `path` 路径下所有的 wav 文件，记录他们的路径\n",
    "# wav_files[0] = 'h:/study/bpfile/dataset/audios/duet/acoustic_guitarviolin/1.wav'\n",
    "for root,dirs,files in os.walk(path, topdown=True):\n",
    "    for name in files:\n",
    "        if '.wav' in name:\n",
    "            wav_files.append(os.path.normcase(root+os.path.sep+name).replace('\\\\','/'))\n",
    "            \n",
    "# 计算 bases 和 labels\n",
    "for i, fname in enumerate(wav_files):\n",
    "    label = np.zeros(1000)   # 1000个乐器类别\n",
    "    \n",
    "    # 每个 wav 对应的 NMF 结果保存为 *.npy 文件，对应路径存入 bases\n",
    "    # bases_filepath[0] = 'h:/study/bpfile/dataset/audios/duet/acoustic_guitarviolin/1_bases.npy'\n",
    "    # np.array(nmf_base[0]).shape = (2401, 16)\n",
    "    nmf_base = audio_import.nmf([fname])\n",
    "    np.save(fname[:-4]+'_bases'+'.npy', nmf_base[0])\n",
    "    bases_filepath.append(fname[:-4]+'_bases'+'.npy')\n",
    "    \n",
    "    # 根据文件路径名确定当前音频中乐器的 label，作为 ground truth 训练\n",
    "    # labels_filepath[0] = 'h:/study/bpfile/dataset/audios/duet/acoustic_guitarviolin/1_labels.npy'\n",
    "    for instrument, index in zip(names, idxs):\n",
    "        if instrument in fname:\n",
    "            label[index] = 1\n",
    "    print(sum(label))\n",
    "    np.save(fname[:-4]+'_labels'+'.npy', label)\n",
    "    labels_filepath.append(fname[:-4]+'_labels'+'.npy')\n",
    "    \n",
    "    print(bases_filepath[-1])\n",
    "    print(labels_filepath[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate `train.h5` and `val.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import random\n",
    "\n",
    "dataset_num = len(wav_files)\n",
    "train_num = int(0.7*dataset_num)\n",
    "\n",
    "# 随机选取 70% 的数据作为验证集\n",
    "train_bases = random.sample(range(dataset_num), train_num)\n",
    "\n",
    "# 路径 utf-8 编码，否则报错\n",
    "train_bases_encode = []\n",
    "train_labels_encode = []\n",
    "val_bases_encode = []\n",
    "val_labels_encode = []\n",
    "for i in range(dataset_num):\n",
    "    if i in train_bases:\n",
    "        train_bases_encode.append(bases_filepath[i].encode(encoding='utf-8', errors='strict'))\n",
    "        train_labels_encode.append(labels_filepath[i].encode(encoding='utf-8', errors='strict'))\n",
    "    else:\n",
    "        val_bases_encode.append(bases_filepath[i].encode(encoding='utf-8', errors='strict'))\n",
    "        val_labels_encode.append(labels_filepath[i].encode(encoding='utf-8', errors='strict'))\n",
    "\n",
    "h5f = h5py.File('dataset/train.h5', 'w')\n",
    "h5f.create_dataset('bases', data=train_bases_encode)\n",
    "h5f.create_dataset('labels', data=train_labels_encode)\n",
    "h5f.close()\n",
    "\n",
    "h5f = h5py.File('dataset/val.h5', 'w')\n",
    "h5f.create_dataset('bases', data=val_bases_encode)\n",
    "h5f.create_dataset('labels', data=val_labels_encode)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process pictures for *test*\n",
    "1. compute **nmf** for all wav files and save as `npy` file\n",
    "2. compute **labels** by feat_extrator and save as `npy` file\n",
    "3. save paths of all `npy` file in `train.h5` and `val.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\torchvision\\models\\densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41638. 28137. 23348. 26450. 21528. 29065. 38568. 18622.]\n",
      "h:/study/bpfile/testset25/testimage/accordion_1_saxophone_1/labels.npy\n",
      "[44184. 22514. 45354. 28776. 23004. 42053. 36036. 49654.]\n",
      "h:/study/bpfile/testset25/testimage/accordion_2_acoustic_guitar_2/labels.npy\n",
      "[ 7318. 10006. 16459. 11275. 19657. 10952.  7481. 12197.]\n",
      "h:/study/bpfile/testset25/testimage/accordion_2_cello_3/labels.npy\n",
      "[42947. 37449. 35432. 34241. 40664. 41247. 40478. 33705.]\n",
      "h:/study/bpfile/testset25/testimage/accordion_3_acoustic_guitar_3/labels.npy\n",
      "[16221. 12031. 14893. 13090. 11563. 16330. 13942. 12595.]\n",
      "h:/study/bpfile/testset25/testimage/accordion_4_saxophone_3/labels.npy\n",
      "[30113. 27039. 24987. 32208. 32384. 29942. 27369. 26171.]\n",
      "h:/study/bpfile/testset25/testimage/accordion_5_cello_1/labels.npy\n",
      "[11254. 16168. 14288. 23516. 14177. 22383. 22966. 27767.]\n",
      "h:/study/bpfile/testset25/testimage/accordion_6_saxophone_2/labels.npy\n",
      "[16209. 20243. 29032. 36223. 23102. 24569. 12941. 37013.]\n",
      "h:/study/bpfile/testset25/testimage/acoustic_guitar_1_violin_2/labels.npy\n",
      "[37100. 51022. 44369. 55322. 61343. 32247. 35826. 43856.]\n",
      "h:/study/bpfile/testset25/testimage/acoustic_guitar_2_violin_1/labels.npy\n",
      "[56747. 37141. 42949. 59703. 69396. 64895. 49706. 30740.]\n",
      "h:/study/bpfile/testset25/testimage/acoustic_guitar_4_flute_2/labels.npy\n",
      "[27313. 32918. 29959. 35768. 43725. 31362. 39750. 29372.]\n",
      "h:/study/bpfile/testset25/testimage/acoustic_guitar_5_violin_3/labels.npy\n",
      "[44923. 45968. 22139. 45538. 46829. 47059. 41627. 35649.]\n",
      "h:/study/bpfile/testset25/testimage/acoustic_guitar_6_flute_3/labels.npy\n",
      "[37934. 16427.  8977. 46501. 37428. 42910. 33954. 15040.]\n",
      "h:/study/bpfile/testset25/testimage/cello_2_flute_2/labels.npy\n",
      "[28634. 17186. 32434. 77464. 79871. 25897. 78371. 30753.]\n",
      "h:/study/bpfile/testset25/testimage/cello_4_flute_5/labels.npy\n",
      "[13273. 12817.  9553.  9387.  8075. 11040. 16499. 10849.]\n",
      "h:/study/bpfile/testset25/testimage/flute_1_xylophone_5/labels.npy\n",
      "[21086. 20587. 19157. 22714. 19322. 17687. 21208. 15129.]\n",
      "h:/study/bpfile/testset25/testimage/flute_2_saxophone_1/labels.npy\n",
      "[20212. 16885. 18836. 17196. 31767. 23282. 21617. 29655.]\n",
      "h:/study/bpfile/testset25/testimage/flute_3_saxophone_3/labels.npy\n",
      "[24075. 46827. 51974. 24869. 31273. 38949. 22329. 45916.]\n",
      "h:/study/bpfile/testset25/testimage/flute_3_trumpet_5/labels.npy\n",
      "[30932. 23365. 23160. 20723. 19653. 20618. 25911. 17652.]\n",
      "h:/study/bpfile/testset25/testimage/flute_3_xylophone_2/labels.npy\n",
      "[22622. 29398. 23760. 39682.  9333. 28005. 38690. 10570.]\n",
      "h:/study/bpfile/testset25/testimage/flute_4_saxophone_2/labels.npy\n",
      "[28033. 26857. 21971. 27266. 27183. 25923. 27608. 27189.]\n",
      "h:/study/bpfile/testset25/testimage/flute_4_trumpet_1/labels.npy\n",
      "[24289. 21237. 10030. 23523. 17301. 22669. 24560. 14062.]\n",
      "h:/study/bpfile/testset25/testimage/flute_5_trumpet_4/labels.npy\n",
      "[43322. 54130. 57017. 51123. 50657. 42578. 43713. 55837.]\n",
      "h:/study/bpfile/testset25/testimage/saxophone_1_violin_4/labels.npy\n",
      "[21075. 35818. 28174. 19536. 17033. 27309. 19655. 27402.]\n",
      "h:/study/bpfile/testset25/testimage/saxophone_2_violin_2/labels.npy\n",
      "[18501.  9701. 10835. 22200. 12405. 12025. 17145.  8092.]\n",
      "h:/study/bpfile/testset25/testimage/saxophone_3_violin_3/labels.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from dataset.NMF import audio_import\n",
    "from util.feat_extractor import load_model, get_CAM, feat_pred\n",
    "\n",
    "idxs=[401,402,486,513,558,642,776,889]\n",
    "names=['accordion','acoustic_guitar','cello','trumpet','flute','xylophone','saxophone','violin']\n",
    "\n",
    "test_path = 'h:/Study/bpfile/testset25/'\n",
    "wav_files = []\n",
    "img_files = []\n",
    "bases_filepath = []\n",
    "labels_filepath = []\n",
    "locations = {}\n",
    "\n",
    "# 寻找音频路径与图片路径\n",
    "# wav_dir = 'h:/Study/bpfile/testset25/testaudio/'\n",
    "# img_dir = 'h:/Study/bpfile/testset25/testimage/'\n",
    "wav_dir = os.path.normcase(os.path.join(test_path, 'gt_audio/')).replace('\\\\','/')\n",
    "img_dir = os.path.normcase(os.path.join(test_path, 'testimage/')).replace('\\\\','/')\n",
    "'''\n",
    "for cur_dir in os.listdir(test_path):\n",
    "    if 'audio' in cur_dir:\n",
    "        os.path.normcase(os.path.join(test_path, cur_dir, '/')).replace('\\\\','/')\n",
    "    if 'image' in cur_dir:\n",
    "        os.path.normcase(os.path.join(test_path, cur_dir, '/')).replace('\\\\','/')\n",
    "'''\n",
    "        \n",
    "# 寻找所有 wav 的文件名、图片文件所在文件夹\n",
    "# wav_files[0] = 'accordion_1_saxophone_1.wav'\n",
    "# img_files[0] = 'accordion_1_saxophone_1'\n",
    "for f in os.listdir(wav_dir):   # 剔除非 wav 文件\n",
    "    if '_gt1.wav' not in f and '_gt2.wav' not in f and '.wav' in f:\n",
    "        wav_files.append(f)\n",
    "for f in os.listdir(img_dir):   # 剔除目录下所有文件，只保留文件夹\n",
    "    if os.path.isdir(img_dir + f):\n",
    "        img_files.append(f)\n",
    "        locations[f+'.mp4'] = []\n",
    "        \n",
    "# 排序确保 wav 文件与图片文件夹相对应\n",
    "wav_files.sort()\n",
    "img_files.sort()\n",
    "load_model()\n",
    "\n",
    "# 计算 bases 和 labels\n",
    "for wav_fname, img_folder in zip(wav_files, img_files):\n",
    "    assert wav_fname[:-4] == img_folder    # 确保 wav 文件与图片文件夹相对应\n",
    "    '''\n",
    "    # 计算 NMF 并将结果保存在 npy 文件中\n",
    "    # bases_filepath[0] = 'h:/Study/bpfile/testset25/testaudio/accordion_1_saxophone_1_bases.npy'\n",
    "    # np.array(nmf_base[0]).shape = (2401, 16)\n",
    "    nmf_base = audio_import.nmf([wav_dir+wav_fname])\n",
    "    np.save(wav_dir+wav_fname[:-4]+'_bases'+'.npy', nmf_base[0])\n",
    "    bases_filepath.append(wav_dir+wav_fname[:-4]+'_bases'+'.npy')\n",
    "    '''\n",
    "    imgs = []\n",
    "    # 获得当前文件夹下所有图片（绝对）路径，并随机抽样\n",
    "    # img_folder = 'accordion_1_saxophone_1'\n",
    "    # imgs[0] = '000001.jpg'\n",
    "    for img in os.listdir(img_dir+img_folder):\n",
    "        if '.jpg' in img or '.png' in img:\n",
    "            imgs.append(img)\n",
    "    imgs = random.sample(imgs, 30)  # 由于图片数量过多，每个视频中只随机抽取 50 张图片进行预测\n",
    "    \n",
    "    probs=np.zeros([8])\n",
    "    location = np.zeros([8])\n",
    "    # 计算图像的 label，并获得每种乐器的定位（列号）\n",
    "    for img in imgs:\n",
    "        probs1 = feat_pred(img_dir+img_folder, img)\n",
    "        probs = probs + np.array(probs1)\n",
    "        #(locate, CAMs, heatmap) = get_CAM(img_dir+img_folder, 'results', img)  # heatmap 保存为文件\n",
    "        locate = get_CAM(img_dir+img_folder, 'results', img)\n",
    "        location = location + locate\n",
    "        '''\n",
    "        print(np.argmax(CAMs))\n",
    "        print(CAMs)\n",
    "        plt.figure()\n",
    "        plt.imshow(0.3*CAMs)\n",
    "        plt.figure()\n",
    "        plt.imshow(heatmap)\n",
    "        '''\n",
    "        \n",
    "    locations[img_folder+'.mp4'] = location\n",
    "    #print(probs)\n",
    "    print(location)\n",
    "    softmax = np.zeros(1000)\n",
    "    #for i in range(len(probs)):\n",
    "    #    softmax[idxs[i]] = probs[i]\n",
    "    #np.save(img_dir+img_folder+'/labels'+'.npy', softmax)\n",
    "    labels_filepath.append(img_dir+img_folder+'/labels'+'.npy')\n",
    "    \n",
    "    #print(bases_filepath[-1])\n",
    "    print(labels_filepath[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "test_bases_encode = []\n",
    "test_labels_encode = []\n",
    "\n",
    "for i in range(len(bases_filepath)):\n",
    "    test_bases_encode.append(bases_filepath[i].encode(encoding='utf-8', errors='strict'))\n",
    "    test_labels_encode.append(labels_filepath[i].encode(encoding='utf-8', errors='strict'))\n",
    "\n",
    "h5f = h5py.File('dataset/test.h5', 'w')\n",
    "h5f.create_dataset('bases', data=test_bases_encode)\n",
    "h5f.create_dataset('labels', data=test_labels_encode)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for k in locations.keys():\n",
    "    locations[k] = list(locations[k])\n",
    "\n",
    "with open('dataset/locations.json','w') as f:\n",
    "    json.dump(locations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8531398e-08, 4.203821e-10, 3.0119654e-07, 1.6685843e-09, 7.592569e-08, 0.58534557, 4.232982e-09, 8.99717e-09]\n",
      "left  [3.3698166e-06, 1.5242497e-08, 1.61589e-05, 3.455999e-08, 1.1760211e-07, 2.40524e-06, 2.1710822e-08, 2.5602446e-06]\n",
      "right  [2.5203516e-08, 9.114263e-12, 1.9799065e-09, 6.485805e-11, 5.8738996e-09, 0.11121938, 1.4527327e-10, 1.1737265e-10]\n",
      "[0, 0, 1, 0, 0, 2, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from util import feat_extractor\n",
    "from util.feat_extractor import feat_pred, feat_pred_by_seg, load_model\n",
    "\n",
    "load_model()\n",
    "img_dir = '.'\n",
    "imgname = '000053.jpg'\n",
    "\n",
    "print(feat_pred(img_dir,imgname))\n",
    "left,right = feat_pred_by_seg(img_dir,imgname)\n",
    "print('left ', left)\n",
    "print('right ', right)\n",
    "\n",
    "position = [0]*8\n",
    "left_max = max(left)\n",
    "right_max = max(right)\n",
    "if left_max > right_max:\n",
    "    position[left.index(left_max)] = 1      # 确定左侧乐器种类\n",
    "    right[left.index(left_max)] = 0\n",
    "    position[right.index(max(right))] = 2   # 确定右侧乐器种类\n",
    "else:\n",
    "    position[right.index(right_max)] = 2    # 确定右侧乐器种类\n",
    "    left[right.index(right_max)] = 0\n",
    "    position[left.index(max(left))] = 1     # 确定左侧乐器种类\n",
    "print(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [11.025667273241673,\n",
       "  -8.616144398241026,\n",
       "  8.70033389108073,\n",
       "  2.5079283361029905,\n",
       "  9.652112032056358,\n",
       "  -0.15310698486073632,\n",
       "  2.05947453003453,\n",
       "  5.1101977566897325,\n",
       "  1.562369217599937,\n",
       "  -1.3130846512270777,\n",
       "  0.9041050961813324,\n",
       "  12.655941904901958,\n",
       "  -13.438770299126723,\n",
       "  8.627968336798402,\n",
       "  -8.309988122393,\n",
       "  7.548632691892022,\n",
       "  2.0753651542099916,\n",
       "  3.9472065291720515,\n",
       "  2.407020892892854,\n",
       "  1.5340932165582575,\n",
       "  -1.489769209593552,\n",
       "  4.694007757740754,\n",
       "  0.7759560881044568,\n",
       "  3.236182103382213,\n",
       "  9.875781822568525,\n",
       "  -8.932016372898001,\n",
       "  -7.911161286186349,\n",
       "  6.71525418993304,\n",
       "  3.171514461085306,\n",
       "  -4.228833308769227,\n",
       "  -3.532583959722861,\n",
       "  2.446789310157182,\n",
       "  -0.4158362013207336,\n",
       "  3.6410206480297926,\n",
       "  -7.14992673159284,\n",
       "  10.78672873386352,\n",
       "  4.3889315979614345,\n",
       "  -5.781894478256094,\n",
       "  6.211971539542357,\n",
       "  -1.0298283188974704,\n",
       "  -0.04018120965681371,\n",
       "  -1.7705561093021722,\n",
       "  -11.368012914148942,\n",
       "  14.822047305213744,\n",
       "  2.481380517704754,\n",
       "  -0.5060000788044992,\n",
       "  9.136656160609991,\n",
       "  -3.96703800321657,\n",
       "  6.488657374146306,\n",
       "  -0.03982178185451063])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Evaluate import Evaluate\n",
    "Evaluate('H:/Study/bpfile/testset25/result_json','H:/Study/bpfile/testset25/Result_sep','H:/Study/bpfile/testset25/gt_audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "1.5873515312450368\n"
     ]
    }
   ],
   "source": [
    "# 2018/12/31 01:00\n",
    "accur = [1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]\n",
    "snr = [11.347610961650894,\n",
    "  -9.632960200620044,\n",
    "  8.70021952059402,\n",
    "  2.5079513008718477,\n",
    "  9.652218240462485,\n",
    "  -0.1527975835486499,\n",
    "  2.0595129473305334,\n",
    "  5.1103995341998925,\n",
    "  1.561645286855171,\n",
    "  -1.313358260349896,\n",
    "  0.9039634811239038,\n",
    "  12.656031646268426,\n",
    "  -13.439097840668804,\n",
    "  8.627718589954496,\n",
    "  -8.30973963605447,\n",
    "  7.548450334721046,\n",
    "  2.0754457673556868,\n",
    "  3.9472773987273646,\n",
    "  2.4069430738422453,\n",
    "  1.534099362765119,\n",
    "  -1.4902245012246584,\n",
    "  4.6937194856242614,\n",
    "  2.605547560421433,\n",
    "  4.373700425100127,\n",
    "  9.875911990888353,\n",
    "  -8.932793377600113,\n",
    "  -7.911671922013421,\n",
    "  6.714576715646839,\n",
    "  2.952031236943138,\n",
    "  -4.591842359176853,\n",
    "  -3.664687551573451,\n",
    "  2.461675985931538,\n",
    "  -0.4154217807845178,\n",
    "  3.641413631044385,\n",
    "  -6.275929831730655,\n",
    "  10.901451073989607,\n",
    "  4.391146147909199,\n",
    "  -5.780470227883133,\n",
    "  6.2859942439767735,\n",
    "  -1.4655790234925066,\n",
    "  -0.03865087571590465,\n",
    "  -1.7699167771162454,\n",
    "  -11.366997010864136,\n",
    "  14.822491686259596,\n",
    "  2.4814621671509456,\n",
    "  -0.5059430078344603,\n",
    "  8.13116251910653,\n",
    "  -4.994748791387616,\n",
    "  6.488218187777051,\n",
    "  -0.03958338260151157]\n",
    "\n",
    "print(sum(accur))\n",
    "print(sum(snr)/len(snr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(snr)):\n",
    "    cnt = cnt + int(snr[i]>0)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5839348409877392\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# 2018/12/31 11:00\n",
    "snr = [11.025667273241673,\n",
    "  -8.616144398241026,\n",
    "  8.70033389108073,\n",
    "  2.5079283361029905,\n",
    "  9.652112032056358,\n",
    "  -0.15310698486073632,\n",
    "  2.05947453003453,\n",
    "  5.1101977566897325,\n",
    "  1.562369217599937,\n",
    "  -1.3130846512270777,\n",
    "  0.9041050961813324,\n",
    "  12.655941904901958,\n",
    "  -13.438770299126723,\n",
    "  8.627968336798402,\n",
    "  -8.309988122393,\n",
    "  7.548632691892022,\n",
    "  2.0753651542099916,\n",
    "  3.9472065291720515,\n",
    "  2.407020892892854,\n",
    "  1.5340932165582575,\n",
    "  -1.489769209593552,\n",
    "  4.694007757740754,\n",
    "  0.7759560881044568,\n",
    "  3.236182103382213,\n",
    "  9.875781822568525,\n",
    "  -8.932016372898001,\n",
    "  -7.911161286186349,\n",
    "  6.71525418993304,\n",
    "  3.171514461085306,\n",
    "  -4.228833308769227,\n",
    "  -3.532583959722861,\n",
    "  2.446789310157182,\n",
    "  -0.4158362013207336,\n",
    "  3.6410206480297926,\n",
    "  -7.14992673159284,\n",
    "  10.78672873386352,\n",
    "  4.3889315979614345,\n",
    "  -5.781894478256094,\n",
    "  6.211971539542357,\n",
    "  -1.0298283188974704,\n",
    "  -0.04018120965681371,\n",
    "  -1.7705561093021722,\n",
    "  -11.368012914148942,\n",
    "  14.822047305213744,\n",
    "  2.481380517704754,\n",
    "  -0.5060000788044992,\n",
    "  9.136656160609991,\n",
    "  -3.96703800321657,\n",
    "  6.488657374146306,\n",
    "  -0.03982178185451063]\n",
    "\n",
    "print(sum(snr)/len(snr))\n",
    "cnt = 0\n",
    "for i in range(len(snr)):\n",
    "    cnt = cnt + int(snr[i]>0)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
